name: Executar Scraper de Preços

on:
  # 1. Permite rodar manualmente pela aba "Actions" do GitHub
  workflow_dispatch:
  
  # 2. Agenda a execução (aqui está a "mágica")
  schedule:
    # Roda a cada 6 horas (nos minutos 0, das horas 0, 6, 12, 18 UTC)
    # Você pode ajustar o '*/6' se quiser (ex: '*/1' para toda hora)
    - cron: '0 */6 * * *'

jobs:
  run-scraper:
    runs-on: ubuntu-latest # Usa um servidor Linux padrão

    steps:
      # 1. Baixa o seu código (scraper.py, requirements.txt, etc)
      - name: Checkout do código
        uses: actions/checkout@v4

      # 2. Configura o Python
      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # Pode ajustar se usar outra versão
          cache: 'pip'

      # 3. (MUITO IMPORTANTE) Instala o Google Chrome
      # O Selenium precisa do Chrome para rodar (para Pichau e Terabyte)
      - name: Instalar Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      # 4. Instala as bibliotecas Python (pandas, selenium, sqlalchemy, etc)
      - name: Instalar dependências
        run: pip install -r requirements.txt
      
      # 5. Roda o seu scraper!
      - name: Executar o scraper.py
        env:
          # Esta linha injeta o segredo (Ação 1) no script
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python scraper.py